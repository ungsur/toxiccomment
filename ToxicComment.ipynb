{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing, sklearn.decomposition,sklearn.linear_model, sklearn.pipeline, sklearn.metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/rungsunan/code/kaggle/toxiccomment/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22256635</td>\n",
       "      <td>Nonsense?  kiss off, geek. what I said is true...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27450690</td>\n",
       "      <td>\"\\n\\n Please do not vandalize pages, as you di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54037174</td>\n",
       "      <td>\"\\n\\n \"\"Points of interest\"\" \\n\\nI removed the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77493077</td>\n",
       "      <td>Asking some his nationality is a Racial offenc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79357270</td>\n",
       "      <td>The reader here is not going by my say so for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                       comment_text  toxic  \\\n",
       "0  22256635  Nonsense?  kiss off, geek. what I said is true...      1   \n",
       "1  27450690  \"\\n\\n Please do not vandalize pages, as you di...      0   \n",
       "2  54037174  \"\\n\\n \"\"Points of interest\"\" \\n\\nI removed the...      0   \n",
       "3  77493077  Asking some his nationality is a Racial offenc...      0   \n",
       "4  79357270  The reader here is not going by my say so for ...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.585100e+04</td>\n",
       "      <td>95851.000000</td>\n",
       "      <td>95851.000000</td>\n",
       "      <td>95851.000000</td>\n",
       "      <td>95851.000000</td>\n",
       "      <td>95851.000000</td>\n",
       "      <td>95851.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.994359e+11</td>\n",
       "      <td>0.096368</td>\n",
       "      <td>0.010068</td>\n",
       "      <td>0.053301</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.049713</td>\n",
       "      <td>0.008492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.890136e+11</td>\n",
       "      <td>0.295097</td>\n",
       "      <td>0.099832</td>\n",
       "      <td>0.224635</td>\n",
       "      <td>0.056320</td>\n",
       "      <td>0.217352</td>\n",
       "      <td>0.091762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.225664e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.473437e+11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.001297e+11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.501088e+11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999882e+11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         toxic  severe_toxic       obscene        threat  \\\n",
       "count  9.585100e+04  95851.000000  95851.000000  95851.000000  95851.000000   \n",
       "mean   4.994359e+11      0.096368      0.010068      0.053301      0.003182   \n",
       "std    2.890136e+11      0.295097      0.099832      0.224635      0.056320   \n",
       "min    2.225664e+07      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    2.473437e+11      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    5.001297e+11      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    7.501088e+11      0.000000      0.000000      0.000000      0.000000   \n",
       "max    9.999882e+11      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "             insult  identity_hate  \n",
       "count  95851.000000   95851.000000  \n",
       "mean       0.049713       0.008492  \n",
       "std        0.217352       0.091762  \n",
       "min        0.000000       0.000000  \n",
       "25%        0.000000       0.000000  \n",
       "50%        0.000000       0.000000  \n",
       "75%        0.000000       0.000000  \n",
       "max        1.000000       1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic    95851\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['toxic']\n",
    "   ].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnshead = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9237, 965, 5109, 305, 4765, 814]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotlist = []\n",
    "for col in columnshead:\n",
    "    plotlist.append(df[col].sum())\n",
    "plotlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos = np.arange(len(columnshead))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x109da93c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAELCAYAAAAhuwopAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAGzNJREFUeJzt3Xm0JWV97vHvQ4OAIpN0Oshgs7wNimRFpUVwSDriVeIAqEQwUYgxkhtxjkkwK9PVkIUxeh1yISEOtEM0KCYQHLFFJRpsmgZtGwRbaRVkaE0U9RoU+N0/6j307sMZdp0+u8853d/PWnudqrfeqv3W2bv2s6tq11upKiRJ6mOnuW6AJGnhMTwkSb0ZHpKk3gwPSVJvhockqTfDQ5LUm+EhSerN8JAk9WZ4SJJ623muGzAq++23Xy1dunSumyFJC8pVV131vapaPF297TY8li5dypo1a+a6GZK0oCT51jD1PGwlSerN8JAk9WZ4SJJ6MzwkSb0ZHpKk3gwPSVJvhockqTfDQ5LUm+EhSeptu73CfGssPfOjc92EoWw8++lz3QRJOyj3PCRJvRkekqTeDA9JUm+GhySpN8NDktSb4SFJ6s3wkCT1ZnhIknozPCRJvRkekqTeDA9JUm+GhySpN8NDktSb4SFJ6s3wkCT1ZnhIknozPCRJvRkekqTeDA9JUm+GhySpN8NDktSb4SFJ6s3wkCT1NtLwSPKqJOuTfDXJB5LslmTfJJcm+Xr7u89A/dcm2ZDk+iRPHSg/Msm6Nu1tSTLKdkuSpjay8EhyAPByYHlVHQEsAk4BzgRWVdUyYFUbJ8nhbfojgOOAc5Isaos7F3gxsKw9jhtVuyVJ0xv1Yaudgd2T7AzcH/gucAKwsk1fCZzYhk8APlhVd1bVjcAG4Kgk+wN7VtUVVVXAewbmkSTNgZGFR1XdDPwt8G3gFuCHVfUpYElV3dKq3QosacMHAN8ZWMRNreyANjy+XJI0R0Z52Gofur2JQ4AHAw9I8vzBOm1PombxOU9PsibJmk2bNs3WYiVJ44zysNWTgRuralNV/Rz4CPA44LZ2KIr29/ZW/2bgoIH5D2xlN7fh8eX3UVXnVdXyqlq+ePHiWV0ZSdJmowyPbwNHJ7l/+3XUscB1wMXAaa3OacBFbfhi4JQkuyY5hO7E+Op2iOuOJEe35Zw6MI8kaQ7sPKoFV9WXknwYWAvcBVwNnAfsAVyQ5EXAt4Dntvrrk1wAXNvqn1FVd7fFvQQ4H9gd+Hh7SJLmyMjCA6Cq/gL4i3HFd9LthUxU/yzgrAnK1wBHzHoDJUkz4hXmkqTeDA9JUm+GhySpN8NDktSb4SFJ6s3wkCT1ZnhIknozPCRJvRkekqTeDA9JUm+GhySpN8NDktSb4SFJ6s3wkCT1ZnhIknozPCRJvRkekqTeDA9JUm+GhySpN8NDktSb4SFJ6s3wkCT1ZnhIknozPCRJvRkekqTeDA9JUm+GhySpN8NDktSb4SFJ6s3wkCT1ZnhIknozPCRJvRkekqTeDA9JUm+GhySpN8NDktTbSMMjyd5JPpzka0muS3JMkn2TXJrk6+3vPgP1X5tkQ5Lrkzx1oPzIJOvatLclySjbLUma2qj3PN4KfKKqHgb8MnAdcCawqqqWAavaOEkOB04BHgEcB5yTZFFbzrnAi4Fl7XHciNstSZrCyMIjyV7ArwDvBKiqn1XVD4ATgJWt2krgxDZ8AvDBqrqzqm4ENgBHJdkf2LOqrqiqAt4zMI8kaQ6Mcs/jEGAT8O4kVyd5R5IHAEuq6pZW51ZgSRs+APjOwPw3tbID2vD48vtIcnqSNUnWbNq0aRZXRZI0aJThsTPwaODcqnoU8BPaIaoxbU+iZusJq+q8qlpeVcsXL148W4uVJI0zVHgkOWSYsnFuAm6qqi+18Q/Thclt7VAU7e/tbfrNwEED8x/Yym5uw+PLJUlzZNg9jwsnKPvwVDNU1a3Ad5Ic1oqOBa4FLgZOa2WnARe14YuBU5Ls2oJpGbC6HeK6I8nR7VdWpw7MI0maAztPNTHJw+h+/bRXkmcPTNoT2G2I5b8MeH+S+wHfBF5IF1gXJHkR8C3guQBVtT7JBXQBcxdwRlXd3ZbzEuB8YHfg4+0hSZojU4YHcBjwDGBv4JkD5T+i++nslKrqGmD5BJOOnaT+WcBZE5SvAY6Y7vkkSdvGlOFRVRcBFyU5pqr+Yxu1SZI0z0235zFmQ5I/AZYOzlNVvzOKRkmS5rdhw+Mi4HLg08Dd09SVJG3nhg2P+1fVH4+0JZKkBWPYn+pekuRpI22JJGnBGDY8XkEXID9NckeSHyW5Y5QNkyTNX0MdtqqqB466IZKkhWOo8EjyKxOVV9XnZ7c5kqSFYNgT5n84MLwbcBRwFfCkWW+RJGneG/aw1eDV5SQ5CHjLSFokSZr3Ztol+03Aw2ezIZKkhWPYcx5vZ/N9N3YCHgmsHVWjJEnz27DnPNYMDN8FfKCqvjCC9kiSFoBhz3msbN2qH9qKrh9dkyRJ892wh61WACuBjUCAg5Kc5k91NVeWnvnRuW7CUDae/fS5boI0EsMetnoT8JSquh4gyaHAB4AjR9UwSdL8NeyvrXYZCw6AqroB2GU0TZIkzXdDnzBP8g7gfW38t9jyJLokaQcybHj8PnAG8PI2fjlwzkhaJEma94YNj52Bt1bVmwGSLAJ2HVmrJEnz2rDnPFYBuw+M7053V0FJ0g5o2PDYrap+PDbShu8/miZJkua7YQ9b/STJo6tqLUCSI4Gfjq5ZkhY6r8XZvg0bHq8EPpTku3QXCf4icPLIWiVJmteG7Z7kyiQPAw5rRddX1c9H1yxJ0nw2ZXgkefYkkw5NQlV9ZARtkiTNc9PteTxzimkFGB6StAOaMjyq6oXbqiGSpIVjqJ/qJlmS5J1JPt7GD0/yotE2TZI0Xw17ncf5wCeBB7fxG+h+gSVJ2gENGx77VdUFwD0AVXUXcPfIWiVJmteGDY+fJHkQ7T7mSY4GfjiyVkmS5rVhLxJ8NXAx8NAkXwAWAyeNrFWSpHlt2IsE1yb5VbqLBIMXCUrSDm3Ye5jvBrwEeALdoavLk/x9Vf33KBsnSZqfhj3n8R7gEcDbgb9rw+8dZsYki5JcneSSNr5vkkuTfL393Weg7muTbEhyfZKnDpQfmWRdm/a2JBl2BSVJs2/Y8Diiql5UVZe1x4vpAmQYrwCuGxg/E1hVVcvo7hNyJnTXjgCntOUeB5zTbjoFcC7wYmBZexw35HNLkkZg2PBY235hBUCSxzLEPcyTHAg8HXjHQPEJwMo2vBI4caD8g1V1Z1XdCGwAjkqyP7BnVV1RVUW3F3QikqQ5M13HiOvoznHsAnwxybfb+EOArw2x/LcAfwQ8cKBsSVXd0oZvBZa04QOAKwbq3dTKft6Gx5dLkubIdCfMnzHTBSd5BnB7VV2VZMVEdaqqktRMn2OC5zwdOB3g4IMPnq3FSpLGma5jxG8Njif5BWC3IZf9eOD4JE9r8+yZ5H3AbUn2r6pb2iGp21v9m4GDBuY/sJXd3IbHl0/U3vOA8wCWL18+a6EkSdrSsB0jHp/k68CNwOeAjcDHp5qnql5bVQdW1VK6E+Gfqarn011seFqrdhpwURu+GDglya5JDqE7Mb66HeK6I8nR7VdWpw7MI0maA8OeMH89cDRwQ1UdAhzLlucn+jgb+J8tjJ7cxqmq9cAFwLXAJ4Azqmqs/6yX0J103wB8g2mCS5I0WsN2T/Lzqvp+kp2S7FRVlyV5y7BPUlWfBT7bhr9PFz4T1TsLOGuC8jXAEcM+nyRptIYNjx8k2QP4PPD+JLcDPxldsyRJ89mwh61OAH4KvIrukNI3mPoWtZKk7diwHSMO7mWsnLSiJGmHMN1Fgj+i3cNj/CS6yzT2HEmrJEnz2nTXeTxwqumSpB3TsOc8JEm6l+EhSerN8JAk9WZ4SJJ6MzwkSb0ZHpKk3gwPSVJvhockqTfDQ5LUm+EhSerN8JAk9WZ4SJJ6MzwkSb0ZHpKk3gwPSVJvhockqTfDQ5LUm+EhSerN8JAk9WZ4SJJ6MzwkSb0ZHpKk3gwPSVJvhockqTfDQ5LUm+EhSerN8JAk9WZ4SJJ6MzwkSb0ZHpKk3gwPSVJvIwuPJAcluSzJtUnWJ3lFK983yaVJvt7+7jMwz2uTbEhyfZKnDpQfmWRdm/a2JBlVuyVJ0xvlnsddwB9U1eHA0cAZSQ4HzgRWVdUyYFUbp007BXgEcBxwTpJFbVnnAi8GlrXHcSNstyRpGiMLj6q6parWtuEfAdcBBwAnACtbtZXAiW34BOCDVXVnVd0IbACOSrI/sGdVXVFVBbxnYB5J0hzYJuc8kiwFHgV8CVhSVbe0SbcCS9rwAcB3Bma7qZUd0IbHl0uS5sjIwyPJHsCFwCur6o7BaW1PombxuU5PsibJmk2bNs3WYiVJ44w0PJLsQhcc76+qj7Ti29qhKNrf21v5zcBBA7Mf2MpubsPjy++jqs6rquVVtXzx4sWztyKSpC2M8tdWAd4JXFdVbx6YdDFwWhs+DbhooPyUJLsmOYTuxPjqdojrjiRHt2WeOjCPJGkO7DzCZT8eeAGwLsk1rexPgLOBC5K8CPgW8FyAqlqf5ALgWrpfap1RVXe3+V4CnA/sDny8PSRJc2Rk4VFV/w5Mdj3GsZPMcxZw1gTla4AjZq91kqSt4RXmkqTeDA9JUm+GhySpN8NDktSb4SFJ6s3wkCT1ZnhIknozPCRJvRkekqTeDA9JUm+GhySpN8NDktSb4SFJ6s3wkCT1ZnhIknozPCRJvRkekqTeDA9JUm+jvIe55omlZ350rpswlI1nP32umyBpSO55SJJ6MzwkSb0ZHpKk3jznIUlD8NzhltzzkCT1ZnhIknozPCRJvRkekqTeDA9JUm+GhySpN8NDktSb4SFJ6s3wkCT1ZnhIknqzexJpHrDrCy007nlIknozPCRJvS2Y8EhyXJLrk2xIcuZct0eSdmQLIjySLAL+L/DrwOHA85IcPretkqQd14IID+AoYENVfbOqfgZ8EDhhjtskSTushRIeBwDfGRi/qZVJkuZAqmqu2zCtJCcBx1XV77bxFwCPraqXjqt3OnB6Gz0MuH6bNnRq+wHfm+tGzKLtbX1g+1un7W19YPtbp/m4Pg+pqsXTVVoo13ncDBw0MH5gK9tCVZ0HnLetGtVHkjVVtXyu2zFbtrf1ge1vnba39YHtb50W8voslMNWVwLLkhyS5H7AKcDFc9wmSdphLYg9j6q6K8lLgU8Ci4B3VdX6OW6WJO2wFkR4AFTVx4CPzXU7tsK8PJy2Fba39YHtb522t/WB7W+dFuz6LIgT5pKk+WWhnPOQJM0jhscMJdk7yUtmOO/yJG+b7TYJkixN8tW5bsdsGXyfJVmR5JIRPc+KJI8bxbKneM4vzvLy7n3tkzwyydNmc/nakuExc3sDMwqPqlpTVS+f5fbMK1v7YZTkdUmePJttWqB6v89adz59rQC2aXhU1Sif75HAtOExWYAlOb9dX9bb+OBKcvxYf3xJTpxp10pJNibZb6btmG2Gx8ydDTw0yTVJ3tgeX02yLsnJAEmelWRVOvsnuSHJLw5+g0yyR5J3t/m+kuQ5c7pWk0jS98cVK9iKD6Oq+vOq+vR09ZK8uv3fv5rkla145yTvT3Jdkg8nuX+re3aSa9v/+W9b2ZIk/5Lky+3xuFb+/CSr2+v7D2MfyEl+nOSsVveKJEta+eIkFya5sj0eP9N1H+fe9xnwRmCPtk5fa+uY9vwbk7whyVrgN5I8NMknklyV5PIkD2v1npnkS0muTvLptv5Lgf8FvKqt7xNnqe1TSvLj9ndFks9Osl4TvWZbfLCPLWdg/H7A64CT2/qcPFkbRhRgWwRXVV1cVWe30RPp+ufbFoYK0BmrKh8zeABLga+24ecAl9L9jHgJ8G1g/zbtfcBLgUuA57WyFcAlbfgNwFsGlrtPz3Y8APgo8GXgq8DJwJHA54Cr6H7evD/wMGD1uPava8P3qd/KPwu8BVgD/AGwGLiQ7rqbK4HHT/G/uZXuQs5rgCe2ss8AXwFWAQe3uhcBp7bh3wPe34bPB05qw48BvtjWcTXwwIF2r2v/gz2A9cCjgBprG/Au4DXAg+h6HBj7kcje7e8/A69sw4uAvYCHA/8G7NLKzxloYwHPbMN/A/xpG/4n4Alt+GDguhG8z1YAP6S7SHYn4D8GnnMj8EcD860ClrXhxwKfGXt/DfwPfhd4Uxv+S+A123gb+vFU6zXFa3bve2Pccgb/V78N/F2PNgT4u/Z8n6b7ZefY+2+q7eMN7T15A937/H502/8muvf+yWNtofsy9Z/AjW3aQ4G1A21ZNjg+QVs3Av8bWEv3vn9YKz+q/c+upttODpukHQ+g2x5Wt7onbNXrty3fLNvTY9wb9f8AvzMw7b3A8W14H7oP0QsHpq9gc3hcNbaRz7AdzwH+cWB8r/YGWtzGT6a7Lob2JjqkDf8x8KfALlPU/yxwzsCyh/6AZNyHEd2H8Wlt+HeAf23DS4ANbcO7Adi3lZ8PnNQ2gm8Cj2nlewI7t+FXAK8beI7XAy8Hvj1Q9iTgX+l+lv7ltvE8G7hfm74J2HVc218KfLf9v66h+0D5yzbtTjZ/mJ0MvKMN3z5Q/5r2mu8xy++zFcClA9POBZ7fhjfSdSsBXZD+dFx7rmvTfgn4FN2Hz/XAJyZ6vbbRNjQYHvdZryles/OZ/fB4Npu/AD4Y+EF7/023fYyF79OAT0/03IPjE7T9MuCRbfivgZdN0daNY9PpDmWOvfcGt4kn0z5rJmjHXw+8X/am294eMNPXb8Fc57GAHQjcAyxJslNV3TPLy18HvCnJG+j2bv4LOAK4tO35LwJuaXUvoHvzn93+nkz3LWWy+tB9Mx/zZODwVg9gzyR7VNUWhw0mcQzdBgpduP4NQFXdluTP6TaiZ1XVf46b7zDglqq6stW/Y4jnGv/786ruQtOjgGPpPhReShcsEwmwsqpeO8G0n1fb+oC72Xyt1E7A0VX130O0b2vcOTA8+PwAPxloyw+q6pETzP924M1VdXGSFXShMR/cZ72meM3uoh1yT7IT3ReMrfUrwAeq6m7gu0k+08qn2z4+0v5eRRdefb0DeGGSV9Ntj0dNU3/w+ca2p72AlUmW0b33d5lk3qcAxyd5TRvfjfYlcAbt9pzHVvgR8MA2fDnd8dVFSRbTvRFXt/ME7wKeR/cCvXqC5VwKnDE2kmSfPo2oqhuAR9OFyF/R7Ymsr6pHtscvVdVTWvV/Bp6b5NBu1vo63QflZPVh8wcSbP6AHKt7wJDBMZ1fAr5P942vj8uBE5PcP8kDgGe1soOTHNPq/Cbw70n2APaq7mLTVwG/3KavAn4fuhPNSfZqZScl+YVWvm+Sh0zTlk8BLxsbSTLRB/dMDL7PhtIC9sYkv9HakiRj67sXm/uFO21rnmfUpnjNNtIdSgI4nok/LGdrfabbPsZCb3yQD+tCuvsUPQO4qqq+P039iZ7v9cBlVXUE8Ey6UJhIgOcMrMvBVTWj4ADDY8bai/yFdD8NPIbuWP6X6Y7r/1FV3Qr8CXB5Vf07XXD8bpKHj1vUXwH7tBO+XwZ+rU87kjwY+H9V9T66E6qPBRaPfXgm2SXJI1qbv0H3pvszNu9RXD9Z/Qn0+YAcv/F+ka5PMoDfovuQp32z/HW6cxWvSXLIuOVcD+yf5DGt/gNbKFNVa+kOA6wGvkT3Le6/2jxnJLmO7rDhua0tlyT5CjD2ekB36OvXkqyj+zZ3eFVdS3dI71Ot/qV0542m8nJgeTuxey3dCeitNu599sYes/4W8KL2nlrP5vvf/CXwoSRXsWVvrv8GPGtbnjAfwmSv2T8Cv9rW7Ri2/IIz5jK6veQpT5gP+DybvwDuz+btsM/2MWaq4NpiWttT/STde/TdQ7RzIoNfCH57inZ8EnjZwI8RHjXD5+vM9nFMH9v2ATyVLriuoTuJvZzuVxafpwuz9cCLB+q/hm7XdulA2YT16Y7pLh+otx9d6HwFuBb4+ynadehAu54IPIRxJ8yBXdtzPrrNczzdRh/ue8L8ilb3CmbhXIIPH1WTnjC/lC1PmE+7fbRtY2Mb3rdti1ucMG/THt+2nauBh7ayo+nuUbRomrZuBPZrw8uBz7bhY+jOX1xN92V0snbsDvwD3VGK9bTzrjN92D2JJM2hdg5ir6r6s7luSx+eMJekOZLkX+h+sjvZjzfmLfc8tFWSvJDuvMGgL1TVGRPVlzS1Fijjz/39cVV9ci7aMxnDQ5LUm7+2kiT1ZnhIknozPKRtIMkr0zpo3MrlLE3ym7PRJmlrGB7StvFKYKvDg64LjJGHR2bWrbt2IIaHFqwkp7Yrur+c5L2tbGmSz7TyVUkObuXnJzk3XTfq32zdgL8rXbft5w8s88fputdfn67L8qNad+HfTHJ8q7Oo1bmyPc/vtfIJuxZP8nK6rlcuS3LZBOvxmCRfbOuxul1FvzRdV+pr22Os6/CzgSe2K6dfNUVbdkpyTmvHpUk+ltaNeZJj03XJvq79D3Zt5YPdup/Z/o61cdnguDTnV3j68DGTB/AIuqtqx664HeuNd7Lee88HPkh3JfEJwB10fWrtRNctyVjPpgX8ehv+F7ouWXah61fpmlZ+Opu7Yt+Vrsv6Q5i+y/T9JliPCXsNpttL2a2VLQPWtOEVDFwZPEVbTqK7Snon4Bfpum05ia7fo+8Ah7Z53sPmLuk3smW37kP3+Opjx3u456GF6knAh6rqewC1uTfeY+i6joeu994nDMzzb1VVdN0z3FZV66rr5Xg9m3tE/RnwiTa8DvhcVf28DY/VeQpwarobNH2J7r4Ty9q01VV1U1vuNUzf0+p9eg2uqrvoAusfW59bH2LyGwhN1pYntP/PPdX1sza2x3MYcGN1HWoCrKTryHPMYC/KYz2+LqLr3uKfkBqvMNeOZKxH0nvYsgvwe9i8LQx2uX5vvaq6J5vvphi6b+FbXLSVrovzqbpM7+NVwG10ezw7AZN19T5ZW2Z6B7nBTgYvBP6Crk+yYXp81Q7EPQ8tVJ+hu93qg6DrNr2VT9h77yz7JPD7SXZpz31oui7hpzJZT6uT9Rq8F90eyT3AC+juIzHRciZryxeA57RzH0voDneNPd/SJP+jjb+A7i5591Gz0+OrtlPueWhBqqr1Sc4CPpfkbroeRX+brsv4dyf5Q7q7BL5wBE//DrrDUWtb99ab6O5NPZXzgE8k+W5V3dvtflX9rHUZ/vYku9PdAfDJdLe+vTDJqXSH0cb2CL4C3N26Iz8feOskbbmQ7iZK19Kd41gL/LCq/rt1KfOhFlJXAn8/RbvfT3eflE9N90/RjsXuSaTtVNpdHtve2Wq6+7rf2nMZC7LHV42eex7S9uuSJHvT/aLr9TMIjgXb46tGzz0PSVJvnjCXJPVmeEiSejM8JEm9GR6SpN4MD0lSb4aHJKm3/w8Vmx3NgXIeNQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109d97438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(y_pos,plotlist,align='center')\n",
    "plt.xticks(y_pos,columnshead)\n",
    "plt.ylabel('labelcount')\n",
    "plt.xlabel('comment category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscene</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>86099</td>\n",
       "      <td>3498</td>\n",
       "      <td>89597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>182</td>\n",
       "      <td>1080</td>\n",
       "      <td>1262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>189</td>\n",
       "      <td>813</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>2667</td>\n",
       "      <td>2795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>757</td>\n",
       "      <td>757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>74</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <td>86614</td>\n",
       "      <td>9237</td>\n",
       "      <td>95851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "toxic                                   0     1    All\n",
       "threat insult obscene severe_toxic                    \n",
       "0      0      0       0             86099  3498  89597\n",
       "                      1                 0    25     25\n",
       "              1       0               182  1080   1262\n",
       "                      1                 0    97     97\n",
       "       1      0       0               189   813   1002\n",
       "                      1                 0    11     11\n",
       "              1       0               128  2667   2795\n",
       "                      1                 0   757    757\n",
       "1      0      0       0                12    74     86\n",
       "                      1                 0     8      8\n",
       "              1       0                 1     8      9\n",
       "                      1                 0     2      2\n",
       "       1      0       0                 2    11     13\n",
       "              1       0                 1   121    122\n",
       "                      1                 0    65     65\n",
       "All                                 86614  9237  95851"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab([df.threat,df.insult,df.obscene,df.severe_toxic],df.toxic, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obscene</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    values\n",
       "obscene        \n",
       "0         90742\n",
       "1          5109"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index=df['obscene'],columns=[ 'values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>severe_toxic</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86614</td>\n",
       "      <td>0</td>\n",
       "      <td>86614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8272</td>\n",
       "      <td>965</td>\n",
       "      <td>9237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>94886</td>\n",
       "      <td>965</td>\n",
       "      <td>95851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "severe_toxic      0    1    All\n",
       "toxic                          \n",
       "0             86614    0  86614\n",
       "1              8272  965   9237\n",
       "All           94886  965  95851"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df.toxic, df.severe_toxic, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>identity_hate</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86551</td>\n",
       "      <td>63</td>\n",
       "      <td>86614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8486</td>\n",
       "      <td>751</td>\n",
       "      <td>9237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>95037</td>\n",
       "      <td>814</td>\n",
       "      <td>95851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "identity_hate      0    1    All\n",
       "toxic                           \n",
       "0              86551   63  86614\n",
       "1               8486  751   9237\n",
       "All            95037  814  95851"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df.toxic, df.identity_hate, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nonsense?  kiss off, geek. what I said is true...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"\\n\\n Please do not vandalize pages, as you di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"\\n\\n \"\"Points of interest\"\" \\n\\nI removed the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asking some his nationality is a Racial offenc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The reader here is not going by my say so for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fried chickens \\n\\nIs dat sum fried chickens?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Why can you put English for example on some pl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Guy Fawkes \\n\\nim a resident in bridgwater and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>as far as nicknames go this article is embarra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Woodland Meadows\\nGood to hear that you correc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"\\n\\nWell I just finished a good bit of editin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Discussion should take place on the article ta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Uh oh, you called my bluff. I am intimidated b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"\\nWe should also contact the living descendan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\" May 2008 (UTC)\\n\\nNotability of Your New Hea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"\\n\\nWhile I agree that this article isn't FA ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>a Turkish citizen and him having received an a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Please explain why censorship of quality addit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>In any case, this edit war will last forever. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"\\n\\n \"\"Vandalism\"\" of George Washington \\n\\nW...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Why hasn't Alitalia been removed rom the allia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"\\n\\n Another AfD stats example \\n\\nI hope you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"\\nI will ;). How about... ah, I've got nothin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\":I have moved some tedious detail in \"\"Survey...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>@AnnieHall, what separates this from capitalis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>.  and its also not random, it was the first c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"\\nThe Graceful Slick....\\nIs non other than a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"====Regarding edits made during December 2 20...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"::The section is now called \"\"Discrepancies a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"\\n\\n Smackdown! \\n\\nGood smackdown on Qatar, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95821</th>\n",
       "      <td>Gods. I'm an Anglo-Norman-ist, really, not an ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95822</th>\n",
       "      <td>\"==T. COTTON LETTER TO THE AYATOLLAHS OF IRAN=...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95823</th>\n",
       "      <td>Much appreciated \\n\\nThank you! Yours is my fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95824</th>\n",
       "      <td>I do apologize once more to you for my unkind ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95825</th>\n",
       "      <td>It has been confirmed that Raul has joined FC ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95826</th>\n",
       "      <td>\"\\nThat an article is \"\"more than a definition...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95827</th>\n",
       "      <td>Calling someone the archetypical unscientific ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95828</th>\n",
       "      <td>Just pointing out that if you intend to keep a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95829</th>\n",
       "      <td>I'm sorry for not noticing that on the article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95830</th>\n",
       "      <td>Can I just say, no-one cares about your opinio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95831</th>\n",
       "      <td>See Wikipedia:Administrators#Misuse_of_adminis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95832</th>\n",
       "      <td>December 2010\\nPlease stop the foolish edits t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95833</th>\n",
       "      <td>Another Unblock Request \\n\\n 137.240.136.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95834</th>\n",
       "      <td>so this can finally be over with</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95835</th>\n",
       "      <td>Oh, okay. Fair enough, then. Thanks for making...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95836</th>\n",
       "      <td>\"\\nI believe you're out of line. You're specul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95837</th>\n",
       "      <td>, 22 April 2007 (UTC)\\n\\nSecond-hander.  21:45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95838</th>\n",
       "      <td>\"\\nIt's staying. Let's move on.  Corbett \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95839</th>\n",
       "      <td>\"\\n\\n Conflict of Interest \\n\\nPm_shef: This i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95840</th>\n",
       "      <td>\"\\nPerhaps the single most potent way to balan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95841</th>\n",
       "      <td>\"\\n Please don't bother. I was just wondering....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95842</th>\n",
       "      <td>The article The eighth sea has been speedily d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95843</th>\n",
       "      <td>Each alum agrees to how much information can b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95844</th>\n",
       "      <td>\"\\n\\n Caucasion vs. white \\n\\nI noticed that t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95845</th>\n",
       "      <td>This culture allows people to hold their wives...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95846</th>\n",
       "      <td>\"\\nI have discussed it, unlike most of those w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95847</th>\n",
       "      <td>ps. Almost forgot, Paine don't reply back to t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95848</th>\n",
       "      <td>Mamoun Darkazanli\\nFor some reason I am unable...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95849</th>\n",
       "      <td>Salafi would be a better term. It is more poli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95850</th>\n",
       "      <td>making wikipedia a better and more inviting pl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95851 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comment_text  toxic\n",
       "0      Nonsense?  kiss off, geek. what I said is true...      1\n",
       "1      \"\\n\\n Please do not vandalize pages, as you di...      0\n",
       "2      \"\\n\\n \"\"Points of interest\"\" \\n\\nI removed the...      0\n",
       "3      Asking some his nationality is a Racial offenc...      0\n",
       "4      The reader here is not going by my say so for ...      0\n",
       "5          Fried chickens \\n\\nIs dat sum fried chickens?      0\n",
       "6      Why can you put English for example on some pl...      0\n",
       "7      Guy Fawkes \\n\\nim a resident in bridgwater and...      0\n",
       "8      as far as nicknames go this article is embarra...      0\n",
       "9      Woodland Meadows\\nGood to hear that you correc...      0\n",
       "10     \"\\n\\nWell I just finished a good bit of editin...      0\n",
       "11     Discussion should take place on the article ta...      0\n",
       "12     Uh oh, you called my bluff. I am intimidated b...      0\n",
       "13     \"\\nWe should also contact the living descendan...      0\n",
       "14     \" May 2008 (UTC)\\n\\nNotability of Your New Hea...      0\n",
       "15     \"\\n\\nWhile I agree that this article isn't FA ...      0\n",
       "16     a Turkish citizen and him having received an a...      0\n",
       "17     Please explain why censorship of quality addit...      0\n",
       "18     In any case, this edit war will last forever. ...      0\n",
       "19     \"\\n\\n \"\"Vandalism\"\" of George Washington \\n\\nW...      0\n",
       "20     Why hasn't Alitalia been removed rom the allia...      1\n",
       "21     \"\\n\\n Another AfD stats example \\n\\nI hope you...      0\n",
       "22     \"\\nI will ;). How about... ah, I've got nothin...      0\n",
       "23     \":I have moved some tedious detail in \"\"Survey...      0\n",
       "24     @AnnieHall, what separates this from capitalis...      0\n",
       "25     .  and its also not random, it was the first c...      0\n",
       "26     \"\\nThe Graceful Slick....\\nIs non other than a...      1\n",
       "27     \"====Regarding edits made during December 2 20...      0\n",
       "28     \"::The section is now called \"\"Discrepancies a...      0\n",
       "29     \"\\n\\n Smackdown! \\n\\nGood smackdown on Qatar, ...      0\n",
       "...                                                  ...    ...\n",
       "95821  Gods. I'm an Anglo-Norman-ist, really, not an ...      0\n",
       "95822  \"==T. COTTON LETTER TO THE AYATOLLAHS OF IRAN=...      0\n",
       "95823  Much appreciated \\n\\nThank you! Yours is my fi...      0\n",
       "95824  I do apologize once more to you for my unkind ...      0\n",
       "95825  It has been confirmed that Raul has joined FC ...      0\n",
       "95826  \"\\nThat an article is \"\"more than a definition...      0\n",
       "95827  Calling someone the archetypical unscientific ...      0\n",
       "95828  Just pointing out that if you intend to keep a...      0\n",
       "95829  I'm sorry for not noticing that on the article...      0\n",
       "95830  Can I just say, no-one cares about your opinio...      0\n",
       "95831  See Wikipedia:Administrators#Misuse_of_adminis...      0\n",
       "95832  December 2010\\nPlease stop the foolish edits t...      0\n",
       "95833        Another Unblock Request \\n\\n 137.240.136.80      0\n",
       "95834                   so this can finally be over with      0\n",
       "95835  Oh, okay. Fair enough, then. Thanks for making...      0\n",
       "95836  \"\\nI believe you're out of line. You're specul...      0\n",
       "95837     , 22 April 2007 (UTC)\\n\\nSecond-hander.  21:45      0\n",
       "95838         \"\\nIt's staying. Let's move on.  Corbett \"      0\n",
       "95839  \"\\n\\n Conflict of Interest \\n\\nPm_shef: This i...      0\n",
       "95840  \"\\nPerhaps the single most potent way to balan...      0\n",
       "95841  \"\\n Please don't bother. I was just wondering....      0\n",
       "95842  The article The eighth sea has been speedily d...      0\n",
       "95843  Each alum agrees to how much information can b...      0\n",
       "95844  \"\\n\\n Caucasion vs. white \\n\\nI noticed that t...      0\n",
       "95845  This culture allows people to hold their wives...      1\n",
       "95846  \"\\nI have discussed it, unlike most of those w...      0\n",
       "95847  ps. Almost forgot, Paine don't reply back to t...      1\n",
       "95848  Mamoun Darkazanli\\nFor some reason I am unable...      0\n",
       "95849  Salafi would be a better term. It is more poli...      0\n",
       "95850  making wikipedia a better and more inviting pl...      0\n",
       "\n",
       "[95851 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['comment_text','toxic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import string\n",
    " \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import os\n",
    "from gensim import corpora, models\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "from sklearn import  svm,neighbors\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas \n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\s+', gaps=True)\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = set(get_stop_words('en'))\n",
    "# print(en_stop)\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_set done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = []\n",
    "punctuation_string = '\\\"?!@#$%^&*()\\';:+,/.-|~=\\\\'\n",
    "table = str.maketrans(dict.fromkeys(punctuation_string))\n",
    "# loop through document list\n",
    "for index, row in df.iterrows():\n",
    "    # clean and tokenize document string\n",
    "    raw = row.comment_text\n",
    "    raw = raw.translate(table)\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    \n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [j for j in tokens if not j in en_stop]\n",
    "    # print(tokens)\n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(k) for k in stopped_tokens]\n",
    "    \n",
    "    # add tokens to list\n",
    "    texts.append((df.toxic[index], stemmed_tokens))\n",
    "\n",
    "print(\"doc_set done!\")\n",
    "os.system('say \"doc set done\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are: 95851 review documents in the dictionary\n",
      "dictionary done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_dictionary = corpora.Dictionary([x[1] for x in texts])\n",
    "print(\"there are: \" + str(len(texts)) + \" review documents in the dictionary\")\n",
    "print(\"dictionary done!\")\n",
    "os.system('say \"Finished dictionary\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corpus(texts_tuple,dictionary):\n",
    "    text_list = [x[1] for x in texts_tuple]\n",
    "    return  [dictionary.doc2bow(text) for text in text_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = dict()\n",
    "def make_model_and_corpus(texts_tuple,num_top, num_pass, model_name,dictionary):\n",
    "    text_list = [x[1] for x in texts_tuple]\n",
    "    temp_corpus = make_corpus(texts_tuple,dictionary)\n",
    "    print(model_name)\n",
    "    temp_model = models.LdaMulticore(corpus=temp_corpus,num_topics=num_top,id2word=dictionary, passes=num_pass)\n",
    "    temp_model_corpus = temp_model[temp_corpus]\n",
    "    temp_outcomes = [x[0] for x in texts_tuple]\n",
    "    model_dict[model_name] = {\"model\": temp_model,\"model_corpus\": temp_model_corpus, \"outcomes\":temp_outcomes}\n",
    "    print(model_dict)\n",
    "    #model_dict[model_name] = {\"model\": models.ldamodel.LdaModel(corpus_name, num_topics=num_top, id2word = dictionary, passes=pass_num)}\n",
    "    \n",
    "    #modelname.save(\"/Users/rungsunan/spyder/yelpproject/\" + str(modelname))\n",
    "    #print(modelname + \" for \" + corpus + \" complete!\")\n",
    "       \n",
    "#make_model_and_corpus(corpus_p,2,5,\"lda_model_corpus_p\")\n",
    "#make_model_and_corpus(corpus_2p,2,5,\"lda_model_corpus_2p\")\n",
    "#make_model_and_corpus(corpus_all,2,5,\"lda_model_corpus_all\")\n",
    "def save_model_and_corpus(modelname):\n",
    "    model_dict[modelname]['model'].save('/Users/rungsunan/code/ADMfinal'+ modelname + '.model')\n",
    "    corpora.SvmLightCorpus.serialize('/Users/rungsunan/code/ADMfinal'+ modelname + '_corpus.svmlight', model_dict[modelname]['model_corpus'],labels=model_dict[modelname]['outcomes'])\n",
    "\n",
    "\n",
    "def load_ldamodel(modelname):\n",
    "    print(modelname)\n",
    "    X_temp, y_temp = load_svmlight_file(\"/Users/rungsunan/code/ADMfinal\" + modelname)\n",
    "    return (X_temp,y_temp)\n",
    "\n",
    "\n",
    "def train_svm(X, y):\n",
    "    \"\"\"\n",
    "    Create and train the Support Vector Machine.\n",
    "    \"\"\"\n",
    "    clf = svm.SVC(kernel='linear')\n",
    "    clf.fit(X, y)\n",
    "    return clf\n",
    "\n",
    "def histo_corpus(modelname):\n",
    "    histo = []\n",
    "    corpus = model_dict[modelname]['model_corpus']\n",
    "    for doc in corpus:\n",
    "        for i in range(len(doc)):\n",
    "            if doc[i][1] > .1:\n",
    "                histo.append(doc[i][0])\n",
    "    return histo\n",
    "\n",
    "\n",
    "def best_topics (texts_tuple, dictionary):\n",
    "    grid = defaultdict(list)\n",
    "    param_list = []\n",
    "    perplex_list = []\n",
    "    perword_list = []\n",
    "    text_list = [x[1] for x in texts_tuple]\n",
    "    temp_corpus = [dictionary.doc2bow(text) for text in text_list]\n",
    "    number_of_words = sum(cnt for document in temp_corpus for _, cnt in document)\n",
    "    parameter_list = [2,3,4,5,10,30,75,120]\n",
    "    for parameter_value in parameter_list:      \n",
    "        print (\"starting pass for parameter_value = %.3f\" % parameter_value)\n",
    "        model = models.LdaMulticore(corpus=temp_corpus, workers=None, id2word=dictionary, num_topics=parameter_value, passes=4, iterations=20)\n",
    "        perplex = model.bound(temp_corpus) # this is model perplexity not the per word perplexity\n",
    "        print (\"Total Perplexity: %s\" % perplex)\n",
    "        param_list.append(parameter_value)\n",
    "        perplex_list.append(perplex)\n",
    "        grid[parameter_value].append(perplex)\n",
    "\n",
    "    \n",
    "        per_word_perplex = np.exp2(-perplex / number_of_words)\n",
    "        perword_list.append(per_word_perplex)\n",
    "        print (\"Per-word Perplexity: %s\" % per_word_perplex)\n",
    "        grid[parameter_value].append(per_word_perplex)\n",
    "        #model.save(data_path + 'ldaMulticore_i10_T' + str(parameter_value) + '_training_corpus.lda')\n",
    "\n",
    "    for numtopics in parameter_list:\n",
    "        print (numtopics, '\\t',  grid[numtopics])\n",
    "    df = pandas.DataFrame(grid)\n",
    "    ax = plt.figure(figsize=(7, 4), dpi=300).add_subplot(111)\n",
    "    df.iloc[1].transpose().plot(ax=ax,  color=\"#254F09\")\n",
    "    plt.xlim(parameter_list[0], parameter_list[-1])\n",
    "    plt.ylabel('Perplexity')\n",
    "    plt.xlabel('topics')\n",
    "    plt.title('')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_set(text_tuple,set_size):\n",
    "    temp_texts = resample(text_tuple, replace = False, n_samples = set_size)\n",
    "    return(temp_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_outcome_p100 = create_sample_set(texts,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_outcome_p100[9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_outcome_p1k = create_sample_set(texts,1000)\n",
    "texts_outcome_p3k = create_sample_set(texts,3000)\n",
    "texts_outcome_p7k = create_sample_set(texts,7000)\n",
    "texts_outcome_p10k = create_sample_set(texts,10000)\n",
    "texts_outcome_p50k = create_sample_set(texts,50000)\n",
    "texts_outcome_all = create_sample_set(texts,len(texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_outcome_p50k = create_sample_set(texts,50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_topics(texts_outcome_p50k, texts_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda_model_p50k_4topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-7b9b0c3c87f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_model_and_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts_outcome_p50k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m  \u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"lda_model_p50k_4topics\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtexts_dictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-04d17a6550f3>\u001b[0m in \u001b[0;36mmake_model_and_corpus\u001b[0;34m(texts_tuple, num_top, num_pass, model_name, dictionary)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtemp_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts_tuple\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtemp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMulticore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp_corpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_top\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_pass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtemp_model_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp_corpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtemp_outcomes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts_tuple\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         )\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;31m# wait for all outstanding jobs to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                 \u001b[0mprocess_result_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreallen\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mprocess_result_queue\u001b[0;34m(force)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_every\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_every\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_updates\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mupdateafter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_docs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlencorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mchunk_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mlog_perplexity\u001b[0;34m(self, chunk, total_docs)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0mcorpus_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0msubsample_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal_docs\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0mperwordbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubsample_ratio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubsample_ratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorpus_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         logger.info(\n\u001b[1;32m    534\u001b[0m             \u001b[0;34m\"%.3f per-word bound, %.1f perplexity estimate based on a held-out corpus of %i documents with %i words\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mbound\u001b[0;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m             \u001b[0;31m# E[log p(doc | theta, beta)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mElogthetad\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mElogbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# E[log p(theta | alpha) - log q(theta | gamma)]; assumes alpha is a vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   1819\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keepdims'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_gentype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sum_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1822\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m             \u001b[0;31m# E[log p(doc | theta, beta)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mElogthetad\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mElogbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# E[log p(theta | alpha) - log q(theta | gamma)]; assumes alpha is a vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/numpy/lib/utils.py\u001b[0m in \u001b[0;36mnewfunc\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;34m\"\"\"`arrayrange` is deprecated, use `arange` instead!\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mnewfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_set_function_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/scipy/special/_logsumexp.py\u001b[0m in \u001b[0;36mlogsumexp\u001b[0;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# suppress warnings about log of zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 279, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 279, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 279, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 279, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 279, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 279, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 279, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/rungsunan/anaconda/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "make_model_and_corpus(texts_outcome_p50k,4  ,10,\"lda_model_p50k_4topics\",texts_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict['lda_model_p50k_4topics']['outcomes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_and_corpus('lda_model_p50k_4topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda_model_p50k_4topics_corpus.svmlight\n"
     ]
    }
   ],
   "source": [
    "(X_p50k_4topics, y_p50k_4topics) = load_ldamodel(\"lda_model_p50k_4topics_corpus.svmlight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p50k_4topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_p50k_4topics, X_test_p50k_4topics, y_train_p50k_4topics, y_test_p50k_4topics = train_test_split(\n",
    "    X_p50k_4topics, y_p50k_4topics, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_p50k_4topics = y_test_p50k_4topics.astype(list).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_p50k_4topics = np.asarray(X_train_p50k_4topics.todense())\n",
    "X_test_p50k_4topics = np.asarray(X_test_p50k_4topics.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_train_p50k_4topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test_p50k_4topics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23453297,  0.        ,  0.46368801,  0.29581983],\n",
       "       [ 0.03609821,  0.03838215,  0.03631072,  0.88920892],\n",
       "       [ 0.36484124,  0.02493716,  0.02422321,  0.58599839],\n",
       "       [ 0.        ,  0.62350352,  0.36578658,  0.        ],\n",
       "       [ 0.        ,  0.13601267,  0.        ,  0.85810119]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_p50k_4topics[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test_p50k_4topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = [1,3,5,7,11,15]\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "knn=KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': [1, 3, 5, 7, 11, 15]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_p50k_4topics,y_p50k_4topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict(X_p50k_4topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
